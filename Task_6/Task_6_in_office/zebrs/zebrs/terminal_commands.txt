PowerShell 7.4.6
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data> scrapy genspider -l
Available templates:
  basic
  crawl
  csvfeed
  xmlfeed
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data>
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data> scrapy startproject zebrs
New Scrapy project 'zebrs', using template directory 'C:\Python312\Lib\site-packages\scrapy\templates\project', created in:
    E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\zebrs

You can start your first spider with:
    cd zebrs
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data> cd Task_6
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6> cd Task_6_in_office
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office> scrapy startproject zebrs
New Scrapy project 'zebrs', using template directory 'C:\Python312\Lib\site-packages\scrapy\templates\project', created in:
    E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs

You can start your first spider with:
    cd zebrs
    scrapy genspider example example.com
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office> cd zebrs
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy genspider -t crawl zebrs_imgs www.zebrs.com
  zebrs.spiders.zebrs_imgs
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_imgs
2024-11-22 14:17:50 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: zebrs)
2024-11-22 14:17:50 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Windows-11-10.0.22631-SP0
2024-11-22 14:17:50 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-22 14:17:50 [asyncio] DEBUG: Using selector: SelectSelector
2024-11-22 14:17:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-11-22 14:17:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-11-22 14:17:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-11-22 14:17:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-11-22 14:17:50 [scrapy.extensions.telnet] INFO: Telnet Password: e553428a8bb2955c
2024-11-22 14:17:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-11-22 14:17:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'zebrs',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'NEWSPIDER_MODULE': 'zebrs.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['zebrs.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-11-22 14:17:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-22 14:17:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-22 14:17:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-22 14:17:51 [scrapy.core.engine] INFO: Spider opened
2024-11-22 14:17:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-22 14:17:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-22 14:17:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/robots.txt> (referer: None)
2024-11-22 14:17:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones> (referer: None)
2024-11-22 14:17:53 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-22 14:17:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 608,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 59292,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.526647,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 22, 11, 17, 53, 599118, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 796894,
 'httpcompression/response_count': 2,
 'items_per_minute': None,
 'log_count/DEBUG': 7,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'responses_per_minute': None,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 22, 11, 17, 51, 72471, tzinfo=datetime.timezone.utc)}
2024-11-22 14:17:53 [scrapy.core.engine] INFO: Spider closed (finished)
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_imgs
2024-11-22 14:18:30 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: zebrs)
2024-11-22 14:18:30 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Windows-11-10.0.22631-SP0
2024-11-22 14:18:30 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-22 14:18:30 [asyncio] DEBUG: Using selector: SelectSelector
2024-11-22 14:18:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-11-22 14:18:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-11-22 14:18:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-11-22 14:18:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-11-22 14:18:30 [scrapy.extensions.telnet] INFO: Telnet Password: 8459a28f08bdbd1c
2024-11-22 14:18:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-11-22 14:18:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'zebrs',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'NEWSPIDER_MODULE': 'zebrs.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['zebrs.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-11-22 14:18:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-22 14:18:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-22 14:18:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-22 14:18:30 [scrapy.core.engine] INFO: Spider opened
2024-11-22 14:18:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-22 14:18:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-22 14:18:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/robots.txt> (referer: None)
2024-11-22 14:18:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones> (referer: None)
2024-11-22 14:18:33 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-22 14:18:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 608,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 59293,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'elapsed_time_seconds': 2.431795,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 22, 11, 18, 33, 424009, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 796897,
 'httpcompression/response_count': 2,
 'items_per_minute': None,
 'log_count/DEBUG': 7,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'responses_per_minute': None,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 11, 22, 11, 18, 30, 992214, tzinfo=datetime.timezone.utc)}
2024-11-22 14:18:33 [scrapy.core.engine] INFO: Spider closed (finished)
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_img
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Python312\Scripts\scrapy.exe\__main__.py", line 7, in <module>
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 187, in execute
    cmd.crawler_process = CrawlerProcess(settings)
                          ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 424, in __init__
    super().__init__(settings)
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 295, in __init__
    self.spider_loader: SpiderLoader = self._get_spider_loader(settings)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 289, in _get_spider_loader
    return cast("SpiderLoader", loader_cls.from_settings(settings.frozencopy()))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 81, in from_settings
    return cls(settings)
           ^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 36, in __init__
    self._load_all_spiders()
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 65, in _load_all_spiders
    for module in walk_modules(name):
                  ^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\utils\misc.py", line 98, in walk_modules
    submod = import_module(fullpath)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\importlib\__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 994, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs\zebrs\spiders\zebrs_imgs.py", line 7, in <module>
    from ..items import ZebrsItem
  File "E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs\zebrs\items.py", line 10
    "name" = scrapy.Field()
    ^^^^^^
SyntaxError: cannot assign to literal here. Maybe you meant '==' instead of '='?
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_img
2024-11-22 14:44:31 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: zebrs)
2024-11-22 14:44:31 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Windows-11-10.0.22631-SP0
Traceback (most recent call last):
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 89, in load
    return self._spiders[spider_name]
           ~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'zebrs_img'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Python312\Scripts\scrapy.exe\__main__.py", line 7, in <module>
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 188, in execute
    _run_print_help(parser, _run_command, cmd, args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 141, in _run_print_help
    func(*a, **kw)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 196, in _run_command
    cmd.run(args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\commands\crawl.py", line 33, in run
    crawl_defer = self.crawler_process.crawl(spname, **opts.spargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 332, in crawl
    crawler = self.create_crawler(crawler_or_spidercls)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 368, in create_crawler
    return self._create_crawler(crawler_or_spidercls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 452, in _create_crawler
    spidercls = self.spider_loader.load(spidercls)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 91, in load
    raise KeyError(f"Spider not found: {spider_name}")
KeyError: 'Spider not found: zebrs_img'
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_imgs
2024-11-22 14:44:47 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: zebrs)
2024-11-22 14:44:47 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:03:25) [MSC v.1937 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Windows-11-10.0.22631-SP0
2024-11-22 14:44:47 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-22 14:44:47 [asyncio] DEBUG: Using selector: SelectSelector
2024-11-22 14:44:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-11-22 14:44:47 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-11-22 14:44:47 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-11-22 14:44:47 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-11-22 14:44:47 [scrapy.extensions.telnet] INFO: Telnet Password: 99e515282e25c04c
2024-11-22 14:44:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-11-22 14:44:47 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'zebrs',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'NEWSPIDER_MODULE': 'zebrs.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['zebrs.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-11-22 14:44:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-22 14:44:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-22 14:44:48 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-11-22 14:44:48 [scrapy.core.engine] INFO: Spider opened
2024-11-22 14:44:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-22 14:44:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-22 14:44:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/robots.txt> (referer: None)
2024-11-22 14:44:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones> (referer: None)
2024-11-22 14:44:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones?page=2> (referer: https://www.zebrs.com/categories/smartphones)
2024-11-22 14:44:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones?page=3> (referer: https://www.zebrs.com/categories/smartphones?page=2)
2024-11-22 14:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones?page=4> (referer: https://www.zebrs.com/categories/smartphones?page=3)
2024-11-22 14:44:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones?page=5> (referer: https://www.zebrs.com/categories/smartphones?page=4)
2024-11-22 14:45:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones?page=6> (referer: https://www.zebrs.com/categories/smartphones?page=5)
2024-11-22 14:45:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.zebrs.com/categories/smartphones?page=7> (referer: https://www.zebrs.com/categories/smartphones?page=6)
2024-11-22 14:45:02 [scrapy.core.engine] INFO: Closing spider (finished)
2024-11-22 14:45:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3259,
 'downloader/request_count': 8,
 'downloader/request_method_count/GET': 8,
 'downloader/response_bytes': 368279,
 'downloader/response_count': 8,
 'downloader/response_status_count/200': 8,
 'elapsed_time_seconds': 14.515735,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 11, 22, 11, 45, 2, 568217, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 5241132,
 'httpcompression/response_count': 8,
 'items_per_minute': None,
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'request_depth_max': 6,
 'response_received_count': 8,
 'responses_per_minute': None,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/200': 1,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2024, 11, 22, 11, 44, 48, 52482, tzinfo=datetime.timezone.utc)}
2024-11-22 14:45:02 [scrapy.core.engine] INFO: Spider closed (finished)
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_imgs -L WARN -scrapy crawl zebrs_img -L WARN -o products.csv
Usage
=====
  scrapy crawl [options] <spider>
crawl: error: Invalid -s value, use -s NAME=VALUE
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_img -L WARN -o products.csv
Traceback (most recent call last):
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 89, in load
    return self._spiders[spider_name]
           ~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'zebrs_img'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Python312\Scripts\scrapy.exe\__main__.py", line 7, in <module>
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 188, in execute
    _run_print_help(parser, _run_command, cmd, args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 141, in _run_print_help
    func(*a, **kw)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 196, in _run_command
    cmd.run(args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\commands\crawl.py", line 33, in run
    crawl_defer = self.crawler_process.crawl(spname, **opts.spargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 332, in crawl
    crawler = self.create_crawler(crawler_or_spidercls)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 368, in create_crawler
    return self._create_crawler(crawler_or_spidercls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 452, in _create_crawler
    spidercls = self.spider_loader.load(spidercls)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 91, in load
    raise KeyError(f"Spider not found: {spider_name}")
KeyError: 'Spider not found: zebrs_img'
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_img -L WARN -o products.csv
Traceback (most recent call last):
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 89, in load
    return self._spiders[spider_name]
           ~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'zebrs_img'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Python312\Scripts\scrapy.exe\__main__.py", line 7, in <module>
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 188, in execute
    _run_print_help(parser, _run_command, cmd, args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 141, in _run_print_help
    func(*a, **kw)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 196, in _run_command
    cmd.run(args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\commands\crawl.py", line 33, in run
    crawl_defer = self.crawler_process.crawl(spname, **opts.spargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 332, in crawl
    crawler = self.create_crawler(crawler_or_spidercls)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 368, in create_crawler
    return self._create_crawler(crawler_or_spidercls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 452, in _create_crawler
    spidercls = self.spider_loader.load(spidercls)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 91, in load
    raise KeyError(f"Spider not found: {spider_name}")
KeyError: 'Spider not found: zebrs_img'
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_img -L WARN -o products.csv
Traceback (most recent call last):
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 89, in load
    return self._spiders[spider_name]
           ~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'zebrs_img'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Python312\Scripts\scrapy.exe\__main__.py", line 7, in <module>
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 188, in execute
    _run_print_help(parser, _run_command, cmd, args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 141, in _run_print_help
    func(*a, **kw)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 196, in _run_command
    cmd.run(args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\commands\crawl.py", line 33, in run
    crawl_defer = self.crawler_process.crawl(spname, **opts.spargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 332, in crawl
    crawler = self.create_crawler(crawler_or_spidercls)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 368, in create_crawler
    return self._create_crawler(crawler_or_spidercls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 452, in _create_crawler
    spidercls = self.spider_loader.load(spidercls)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 91, in load
    raise KeyError(f"Spider not found: {spider_name}")
KeyError: 'Spider not found: zebrs_img'
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_img -L WARN -o products.csv
Traceback (most recent call last):
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 89, in load
    return self._spiders[spider_name]
           ~~~~~~~~~~~~~^^^^^^^^^^^^^
KeyError: 'zebrs_img'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\Python312\Scripts\scrapy.exe\__main__.py", line 7, in <module>
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 188, in execute
    _run_print_help(parser, _run_command, cmd, args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 141, in _run_print_help
    func(*a, **kw)
  File "C:\Python312\Lib\site-packages\scrapy\cmdline.py", line 196, in _run_command
    cmd.run(args, opts)
  File "C:\Python312\Lib\site-packages\scrapy\commands\crawl.py", line 33, in run
    crawl_defer = self.crawler_process.crawl(spname, **opts.spargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 332, in crawl
    crawler = self.create_crawler(crawler_or_spidercls)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 368, in create_crawler
    return self._create_crawler(crawler_or_spidercls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\crawler.py", line 452, in _create_crawler
    spidercls = self.spider_loader.load(spidercls)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python312\Lib\site-packages\scrapy\spiderloader.py", line 91, in load
    raise KeyError(f"Spider not found: {spider_name}")
KeyError: 'Spider not found: zebrs_img'
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs> scrapy crawl zebrs_imgs -L WARN -o products.csv
PS E:\Курс_DataScience_GeekBarains\Вторая_четверть\Сбор и разметка данных\Collection_data\Task_6\Task_6_in_office\zebrs>
